{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133d6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262, 224, 224)\n",
      "(262, 224, 224, 3)\n",
      "(262, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, WeightedRandomSampler\n",
    "\n",
    "\n",
    "from torch.nn import Conv2d\n",
    "from torch import optim\n",
    "\n",
    "import pretrained_microscopy_models as pmm\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Processed_Data2\", \"rb\") as fp:   # Unpickling\n",
    "  MoS2_data = pickle.load(fp)\n",
    "\n",
    "df = pd.DataFrame(MoS2_data)\n",
    "T = df['T']\n",
    "\n",
    "T_classes = {900.0: 0, 950.0: 1, 1000.0: 2}\n",
    "#print(MoS2_activities_substrate2['T'])\n",
    "T_target = [T_classes[T[index]] for index, item in enumerate(T)]\n",
    "sampleId = df['sampleId']\n",
    "sampleLabel = df['sampleLabel']\n",
    "data_image = np.array([np.array(item) for item in df['image']])\n",
    "\n",
    "\n",
    "Data_CNN = data_image\n",
    "print(Data_CNN.shape)\n",
    "Data_CNN_rgb = np.repeat(Data_CNN[..., np.newaxis], 3, -1)\n",
    "print(Data_CNN_rgb.shape)\n",
    "Data_CNN_rgb = Data_CNN_rgb.transpose(0, 3, 1, 2)/255\n",
    "print(Data_CNN_rgb.shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.ToPILImage(),\n",
    "      transforms.RandomRotation(degrees= (0, 180)),\n",
    "      transforms.RandomHorizontalFlip(0.5),\n",
    "      transforms.RandomVerticalFlip(0.5),\n",
    "      transforms.ToTensor(),\n",
    "      #transforms.Normalize(mean=mean, std=std),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "      transforms.ToPILImage(),\n",
    "      transforms.ToTensor(),\n",
    "      #transforms.Normalize(mean=mean, std=std),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "class Dataset():\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels, transform):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples' \n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.transform(ID)\n",
    "        y = self.labels[index]\n",
    "        return X, y      \n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def data_loader_fn(x, y, transform, batch_size):\n",
    "    target = np.array(y)\n",
    "    data = np.array(x)\n",
    "    labels_unique, class_sample_count = np.unique(target, return_counts=True)\n",
    "    weight = [sum(class_sample_count) / c for c in class_sample_count]\n",
    "\n",
    "\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    target = torch.from_numpy(target)\n",
    "    data = torch.from_numpy(data)\n",
    "    #train_dataset = torch.utils.data.TensorDataset(data, target)\n",
    "\n",
    "    dataset = Dataset(data, target, transform)\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=1, sampler=sampler, drop_last=False)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def data_loader_test_fn(x, y, transform, batch_size):\n",
    "    data = torch.tensor(x)\n",
    "    target = torch.tensor(y)\n",
    "    dataset = Dataset(data, target, transform)\n",
    "\n",
    "    data_loader = DataLoader(dataset,  batch_size = batch_size, shuffle = False, drop_last=False)#, num_workers= 2)\n",
    "    return data_loader\n",
    "\n",
    "def accuracy_cnn_fn(trained_model, data_loader, data_type):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    trained_model.eval()\n",
    "    #with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = trained_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the {total} {data_type} images: {accuracy :.1f} %')\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def pretrained_model_image(drop_out):\n",
    "    \n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "    model.fc = nn.Sequential(nn.ReLU(),\n",
    "                                   nn.Dropout(p=drop_out),\n",
    "                                    nn.Linear(512, 100), #150, 50176\n",
    "                                     #nn.ReLU(),\n",
    "                                     nn.Dropout(p=drop_out),\n",
    "                                     #nn.Linear(200, 100),\n",
    "                                     nn.ReLU(),\n",
    "                                     #nn.Dropout(p=drop_out),\n",
    "                                     nn.Linear(100, 3)\n",
    "                                     )\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def pretrained_model_micro(drop_out):\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
    "    url = pmm.util.get_pretrained_microscopynet_url('resnet18', 'micronet')\n",
    "    map_location=torch.device('cpu')\n",
    "    model.load_state_dict(model_zoo.load_url(url))\n",
    "\n",
    "\n",
    "    model.fc = nn.Sequential(nn.ReLU(),\n",
    "                                   nn.Dropout(p=drop_out),\n",
    "                                    nn.Linear(512, 100), #150, 50176\n",
    "                                     #nn.ReLU(),\n",
    "                                     nn.Dropout(p=drop_out),\n",
    "                                     #nn.Linear(200, 100),\n",
    "                                     nn.ReLU(),\n",
    "                                     #nn.Dropout(p=drop_out),\n",
    "                                     nn.Linear(100, 3)\n",
    "                                     )\n",
    "    model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfb2e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Dropout(p=0.35, inplace=False)\n",
      "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (3): Dropout(p=0.35, inplace=False)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.35, inplace=False)\n",
       "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (3): Dropout(p=0.35, inplace=False)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Model/Final_MoS2_ImageNet_best_variables\", \"rb\") as fp:   # Unpickling\n",
    "    best_variables = pickle.load(fp)\n",
    "\n",
    "\n",
    "fold = 9\n",
    "drop_out = best_variables[fold]['drop_out']\n",
    "learning_rate = best_variables[fold]['learning_rate']\n",
    "batch_size = best_variables[fold]['batch_size']\n",
    "epochs = best_variables[fold]['epochs']\n",
    "print(drop_out)\n",
    "\n",
    "model_image = pretrained_model_image(drop_out)\n",
    "print(model_image)\n",
    "\n",
    "PATH = f'Model/Final_MoS2_ImageNet_{fold}_class_T.pth'\n",
    "\n",
    "model_image.load_state_dict(torch.load(PATH))\n",
    "model_image.eval()\n",
    "model_image.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29e438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Model/Final_MoS2_MicroNet_best_variables\", \"rb\") as fp:   # Unpickling\n",
    "    best_variables = pickle.load(fp)\n",
    "\n",
    "\n",
    "fold = 7\n",
    "drop_out = best_variables[fold]['drop_out']\n",
    "learning_rate = best_variables[fold]['learning_rate']\n",
    "batch_size = best_variables[fold]['batch_size']\n",
    "epochs = best_variables[fold]['epochs']\n",
    "print(drop_out)\n",
    "\n",
    "model_micro = pretrained_model_image(drop_out)\n",
    "print(model_micro)\n",
    "\n",
    "PATH = f'Model/Final_MoS2_MicroNet_{fold}_class_T.pth'\n",
    "\n",
    "model_micro.load_state_dict(torch.load(PATH))\n",
    "model_micro.eval()\n",
    "model_micro.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98169a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "\n",
    "# Choose a specific layer to extract features from\n",
    "def get_features_from_model(model, images):\n",
    "    model.eval()\n",
    "    # Choose a specific layer to extract features from\n",
    "    target_layer = model.fc[2]  # can be layer1 - layer4, avgpool\n",
    "\n",
    "    # Define a hook to capture the activations from the target layer\n",
    "\n",
    "    activations = []\n",
    "\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "\n",
    "\n",
    "    hook = target_layer.register_forward_hook(hook_fn)\n",
    "\n",
    "    # Load and preprocess an image\n",
    "\n",
    "\n",
    "    #def get_features(images):\n",
    "    for image in images:\n",
    "   \n",
    "        item_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "        input_batch = item_tensor.unsqueeze(0)     \n",
    "    # Pass the input through the model to trigger the hook and capture activations\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            _ = model(input_batch)\n",
    "\n",
    "\n",
    "    # Remove the hook to prevent memory leaks\n",
    "\n",
    "    hook.remove()\n",
    " \n",
    "\n",
    "# The activations list now contains the convolutional activations from the target layer\n",
    "    return activations\n",
    "\n",
    "# Use \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0584cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "262\n",
      "(262, 100)\n"
     ]
    }
   ],
   "source": [
    "activations = get_features_from_model(model_image, Data_CNN_rgb)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_ImageNet = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_ImageNet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528ff306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "262\n",
      "(262, 100)\n"
     ]
    }
   ],
   "source": [
    "activations = get_features_from_model(model_micro, Data_CNN_rgb)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_MicroNet = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_MicroNet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bf5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "MoS2_Class_Data = []\n",
    "for index, sample in enumerate(sampleId):\n",
    "    this_item = {}\n",
    "\n",
    "    this_item['sampleId'] = sample\n",
    "    this_item['sampleLabel'] = sampleLabel[index]\n",
    "    this_item['image'] = data_image[index]\n",
    "    this_item['T'] = T[index]\n",
    "    #this_item['substrate'] = substrate[index2]\n",
    "    this_item['ImageNet'] = flattened_ImageNet[index]\n",
    "    this_item['MicroNet'] = flattened_MicroNet[index]\n",
    "\n",
    "    MoS2_Class_Data.append(this_item)\n",
    "\n",
    "    #break\n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "print(len(MoS2_Class_Data))  \n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Data_trained2\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(MoS2_Class_Data, fp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfa567",
   "metadata": {},
   "source": [
    "# Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e30c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "#MoS2_data_aug_imagenet_cnn\n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Augmented_Data\", \"rb\") as fp:   # Unpickling\n",
    "  MoS2_data_aug_imagenet_cnn = pickle.load(fp)\n",
    "\n",
    "df = pd.DataFrame(MoS2_data_aug_imagenet_cnn)\n",
    "aug_images = np.array(df['image'].tolist())\n",
    "#aug_images = np.array([item for item in images])\n",
    "Temp_target = df['T']\n",
    "T_target = np.array(Temp_target)\n",
    "sampleId = np.array(df['sampleId'].tolist())\n",
    "\n",
    "print(aug_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34431966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "707\n",
      "(707, 100)\n"
     ]
    }
   ],
   "source": [
    "activations = get_features_from_model(model_image, aug_images)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_aug_ImageNet = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_aug_ImageNet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf44bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "707\n",
      "(707, 100)\n"
     ]
    }
   ],
   "source": [
    "activations = get_features_from_model(model_micro, aug_images)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_aug_MicroNet = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_aug_MicroNet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e520048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707\n"
     ]
    }
   ],
   "source": [
    "MoS2_Class_Data = []\n",
    "\n",
    "\n",
    "\n",
    "for index, sample in enumerate(sampleId):\n",
    "    this_item = {}\n",
    "\n",
    "    this_item['sampleId'] = sample\n",
    "   \n",
    "    this_item['image'] = aug_images[index]\n",
    "    this_item['T'] = Temp_target[index]\n",
    "   \n",
    "    this_item['ImageNet'] = flattened_aug_ImageNet[index]\n",
    "    this_item['MicroNet'] = flattened_aug_MicroNet[index]\n",
    "\n",
    "    MoS2_Class_Data.append(this_item)\n",
    "\n",
    "\n",
    "             \n",
    "print(len(MoS2_Class_Data))  \n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Augmented_trained\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(MoS2_Class_Data, fp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca8a71",
   "metadata": {},
   "source": [
    "# Cropped Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be237c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(699, 224, 224)\n",
      "(699, 224, 224, 3)\n",
      "cropped_images.shape (699, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#MoS2_balanced_data_temp\n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Cropped_Data\", \"rb\") as fp:   # Unpickling\n",
    "  MoS2_balanced_data_temp = pickle.load(fp)\n",
    "\n",
    "df_Temp = pd.DataFrame(MoS2_balanced_data_temp)\n",
    "sampleId = np.array(df_Temp['sampleId'])\n",
    "T_target = df_Temp['T'].tolist()#[item for item in df_Temp['T']]\n",
    "#T_target = np.array(T_target).reshape(len(T_target),1)\n",
    "images_cropped = np.array(df_Temp['image'].tolist())#np.array([np.array(item) for item in df_Temp['image']])\n",
    "\n",
    "\n",
    "print(type(T_target))\n",
    "\n",
    "Data_CNN = images_cropped\n",
    "print(Data_CNN.shape)\n",
    "Data_CNN_rgb = np.repeat(Data_CNN[..., np.newaxis], 3, -1)\n",
    "print(Data_CNN_rgb.shape)\n",
    "cropped_images = Data_CNN_rgb.transpose(0, 3, 1, 2)/255\n",
    "print('cropped_images.shape', cropped_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbdad35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "699\n",
      "(699, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activations = get_features_from_model(model_micro, cropped_images)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_MicroNet_cropped = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_MicroNet_cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44854084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "699\n",
      "(699, 100)\n"
     ]
    }
   ],
   "source": [
    "activations = get_features_from_model(model_image, cropped_images)\n",
    "print(activations[0].shape)\n",
    "print(len(activations))\n",
    "flattened_ImageNet_cropped = np.array([a.numpy() for a in activations]).reshape(len(activations),-1)\n",
    "print(flattened_ImageNet_cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a91f8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n"
     ]
    }
   ],
   "source": [
    "MoS2_Class_Data = []\n",
    "\n",
    "\n",
    "\n",
    "for index, sample in enumerate(sampleId):\n",
    "    this_item = {}\n",
    "\n",
    "    this_item['sampleId'] = sample\n",
    "   \n",
    "    this_item['image'] = cropped_images[index]\n",
    "    this_item['T'] = T_target[index]\n",
    "   \n",
    "    this_item['ImageNet'] = flattened_ImageNet_cropped[index]\n",
    "    this_item['MicroNet'] = flattened_MicroNet_cropped[index]\n",
    "\n",
    "    MoS2_Class_Data.append(this_item)\n",
    "\n",
    "\n",
    "             \n",
    "print(len(MoS2_Class_Data))  \n",
    "\n",
    "with open(\"Data/MoS2_Analysis_Cropped_trained\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(MoS2_Class_Data, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2595bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchvision] *",
   "language": "python",
   "name": "conda-env-torchvision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
