{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3793e0d",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66abb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "from codes.utils import stratified_train_test_group_kfold\n",
    "from codes.utils import model_test_classification\n",
    "from codes.utils import accuracy_classification\n",
    "from codes.utils import cnn_class_cross_val_final_test\n",
    "\n",
    "from codes.classification_codes import cnn_class_gridsearch\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc4319",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f678d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "(262, 224, 224)\n",
      "(262, 224, 224, 3)\n",
      "(262, 3, 224, 224)\n",
      "<class 'generator'>\n",
      "(235, 3, 224, 224)\n",
      "(235,)\n",
      "(27, 3, 224, 224)\n",
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"Data/MoS2_Analysis_Processed_Data2\", \"rb\") as fp:   # Unpickling\n",
    "  MoS2_data = pickle.load(fp)\n",
    "\n",
    "df = pd.DataFrame(MoS2_data)\n",
    "T = df['T']\n",
    "\n",
    "T_classes = {900.0: 0, 950.0: 1, 1000.0: 2}\n",
    "\n",
    "T_target = [T_classes[T[index]] for index, item in enumerate(T)]\n",
    "sampleId = df['sampleId']\n",
    "data_image = np.array([np.array(item) for item in df['image']])\n",
    "\n",
    "print(len(T_target))\n",
    "\n",
    "Data_CNN = data_image\n",
    "print(Data_CNN.shape)\n",
    "Data_CNN_rgb = np.repeat(Data_CNN[..., np.newaxis], 3, -1)\n",
    "print(Data_CNN_rgb.shape)\n",
    "Data_CNN_rgb = Data_CNN_rgb.transpose(0, 3, 1, 2)/255\n",
    "print(Data_CNN_rgb.shape)\n",
    "\n",
    "\n",
    "X = Data_CNN_rgb\n",
    "Y = np.array(T_target)\n",
    "#Y = Y.flatten()\n",
    "groups = np.array(sampleId)\n",
    "\n",
    "train_val_groups, train_val_X, train_val_Y, test_X, test_Y = stratified_train_test_group_kfold(X, Y, groups, n_splits=10, test_fold=0)\n",
    "\n",
    "\n",
    "#Y = Y.flatten()\n",
    "\n",
    "\n",
    "\n",
    "print(train_val_X.shape)\n",
    "print(train_val_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "\n",
    "\n",
    "def pretrained_model():\n",
    "    \n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "    model.fc = nn.Sequential(nn.ReLU(),\n",
    "                          \n",
    "                                    nn.Linear(512, 3) #150, 50176\n",
    "                                   \n",
    "                                     )\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e340782",
   "metadata": {},
   "source": [
    "# 3. Runing Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ee7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "Epoch1: loss: 0.8901 val_loss: 1.1540\n",
      "Epoch2: loss: 0.7929 val_loss: 0.9407\n",
      "Epoch3: loss: 0.6567 val_loss: 0.8955\n",
      "Epoch4: loss: 0.5437 val_loss: 0.9946\n",
      "Epoch5: loss: 0.4724 val_loss: 1.0465\n",
      "Epoch6: loss: 0.4935 val_loss: 1.0627\n",
      "Epoch7: loss: 0.4376 val_loss: 0.8607\n",
      "Epoch8: loss: 0.4018 val_loss: 1.1587\n",
      "Epoch9: loss: 0.2632 val_loss: 1.2487\n",
      "Epoch10: loss: 0.3014 val_loss: 0.9861\n",
      "Epoch11: loss: 0.2754 val_loss: 1.2895\n",
      "Epoch12: loss: 0.2450 val_loss: 1.2130\n",
      "Epoch13: loss: 0.2990 val_loss: 1.3157\n",
      "Epoch14: loss: 0.2988 val_loss: 1.1556\n",
      "Epoch15: loss: 0.2757 val_loss: 1.2990\n",
      "Epoch16: loss: 0.2728 val_loss: 0.8784\n",
      "Epoch17: loss: 0.2427 val_loss: 1.6676\n",
      "Epoch18: loss: 0.1958 val_loss: 1.4570\n",
      "Epoch19: loss: 0.2202 val_loss: 1.6524\n",
      "Epoch20: loss: 0.1583 val_loss: 1.1217\n",
      "Epoch21: loss: 0.2076 val_loss: 1.3620\n",
      "Epoch22: loss: 0.1744 val_loss: 1.3910\n",
      "Epoch23: loss: 0.2433 val_loss: 1.0945\n",
      "Early stopped training at epoch 23\n",
      "Accuracy of the network on the 211 train images: 94.3 %\n",
      "Accuracy of the network on the 24 val images: 66.7 %\n",
      "f1score of the network on the train: 0.92 \n",
      "f1score of the network on the val: 0.70 \n",
      "fold: 0 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.9142 val_loss: 0.8752\n",
      "Epoch2: loss: 0.7266 val_loss: 0.9338\n",
      "Epoch3: loss: 0.6616 val_loss: 1.1261\n",
      "Epoch4: loss: 0.5000 val_loss: 0.9940\n",
      "Epoch5: loss: 0.4810 val_loss: 0.8651\n",
      "Epoch6: loss: 0.4112 val_loss: 1.1120\n",
      "Epoch7: loss: 0.4187 val_loss: 0.9385\n",
      "Epoch8: loss: 0.4923 val_loss: 0.9356\n",
      "Epoch9: loss: 0.3151 val_loss: 1.0897\n",
      "Epoch10: loss: 0.3490 val_loss: 1.1586\n",
      "Epoch11: loss: 0.3117 val_loss: 1.2243\n",
      "Epoch12: loss: 0.3397 val_loss: 0.8818\n",
      "Epoch13: loss: 0.2912 val_loss: 1.3439\n",
      "Epoch14: loss: 0.2394 val_loss: 1.1443\n",
      "Epoch15: loss: 0.1886 val_loss: 1.4424\n",
      "Epoch16: loss: 0.1884 val_loss: 1.0000\n",
      "Epoch17: loss: 0.2351 val_loss: 1.1702\n",
      "Epoch18: loss: 0.2687 val_loss: 1.1631\n",
      "Epoch19: loss: 0.2106 val_loss: 1.5095\n",
      "Epoch20: loss: 0.1190 val_loss: 1.2446\n",
      "Epoch21: loss: 0.1352 val_loss: 1.5095\n",
      "Early stopped training at epoch 21\n",
      "Accuracy of the network on the 211 train images: 96.7 %\n",
      "Accuracy of the network on the 24 val images: 70.8 %\n",
      "f1score of the network on the train: 0.94 \n",
      "f1score of the network on the val: 0.71 \n",
      "fold: 1 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 1.0024 val_loss: 1.1077\n",
      "Epoch2: loss: 0.6779 val_loss: 1.0946\n",
      "Epoch3: loss: 0.6579 val_loss: 1.1581\n",
      "Epoch4: loss: 0.6097 val_loss: 1.0925\n",
      "Epoch5: loss: 0.4579 val_loss: 1.0567\n",
      "Epoch6: loss: 0.4414 val_loss: 1.3123\n",
      "Epoch7: loss: 0.3856 val_loss: 1.3063\n",
      "Epoch8: loss: 0.3837 val_loss: 1.3760\n",
      "Epoch9: loss: 0.3538 val_loss: 1.3499\n",
      "Epoch10: loss: 0.3697 val_loss: 1.0677\n",
      "Epoch11: loss: 0.3691 val_loss: 1.1489\n",
      "Epoch12: loss: 0.2938 val_loss: 1.2508\n",
      "Epoch13: loss: 0.2566 val_loss: 1.1652\n",
      "Epoch14: loss: 0.2317 val_loss: 1.3839\n",
      "Epoch15: loss: 0.2286 val_loss: 1.2507\n",
      "Epoch16: loss: 0.2263 val_loss: 1.1225\n",
      "Epoch17: loss: 0.1894 val_loss: 1.1548\n",
      "Epoch18: loss: 0.2178 val_loss: 1.3014\n",
      "Epoch19: loss: 0.1692 val_loss: 1.2191\n",
      "Epoch20: loss: 0.2119 val_loss: 1.0539\n",
      "Epoch21: loss: 0.1502 val_loss: 1.1002\n",
      "Epoch22: loss: 0.1632 val_loss: 1.3241\n",
      "Epoch23: loss: 0.1401 val_loss: 1.5071\n",
      "Epoch24: loss: 0.1498 val_loss: 1.5326\n",
      "Epoch25: loss: 0.1595 val_loss: 1.7710\n",
      "Epoch26: loss: 0.1084 val_loss: 2.0428\n",
      "Epoch27: loss: 0.1571 val_loss: 1.7171\n",
      "Epoch28: loss: 0.2488 val_loss: 1.7543\n",
      "Epoch29: loss: 0.1242 val_loss: 1.9684\n",
      "Epoch30: loss: 0.1061 val_loss: 2.3029\n",
      "Epoch31: loss: 0.1422 val_loss: 2.4868\n",
      "Epoch32: loss: 0.1704 val_loss: 2.0392\n",
      "Epoch33: loss: 0.1345 val_loss: 2.3292\n",
      "Epoch34: loss: 0.2097 val_loss: 1.8654\n",
      "Epoch35: loss: 0.2525 val_loss: 1.6300\n",
      "Epoch36: loss: 0.1123 val_loss: 1.7495\n",
      "Early stopped training at epoch 36\n",
      "Accuracy of the network on the 211 train images: 98.1 %\n",
      "Accuracy of the network on the 24 val images: 62.5 %\n",
      "f1score of the network on the train: 0.98 \n",
      "f1score of the network on the val: 0.59 \n",
      "fold: 2 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 1.2104 val_loss: 1.2420\n",
      "Epoch2: loss: 0.9327 val_loss: 1.0353\n",
      "Epoch3: loss: 0.6789 val_loss: 1.1696\n",
      "Epoch4: loss: 0.6134 val_loss: 1.1692\n",
      "Epoch5: loss: 0.5333 val_loss: 1.0996\n",
      "Epoch6: loss: 0.4373 val_loss: 1.1829\n",
      "Epoch7: loss: 0.3789 val_loss: 1.2852\n",
      "Epoch8: loss: 0.3772 val_loss: 1.1149\n",
      "Epoch9: loss: 0.3466 val_loss: 1.3338\n",
      "Epoch10: loss: 0.2997 val_loss: 1.5088\n",
      "Epoch11: loss: 0.3181 val_loss: 0.9569\n",
      "Epoch12: loss: 0.2377 val_loss: 1.2373\n",
      "Epoch13: loss: 0.2989 val_loss: 0.9371\n",
      "Epoch14: loss: 0.2348 val_loss: 1.2558\n",
      "Epoch15: loss: 0.2708 val_loss: 1.2723\n",
      "Epoch16: loss: 0.2620 val_loss: 1.3676\n",
      "Epoch17: loss: 0.2355 val_loss: 1.5365\n",
      "Epoch18: loss: 0.2085 val_loss: 1.6010\n",
      "Epoch19: loss: 0.2073 val_loss: 1.1678\n",
      "Epoch20: loss: 0.1761 val_loss: 1.3561\n",
      "Epoch21: loss: 0.1733 val_loss: 0.9679\n",
      "Epoch22: loss: 0.1683 val_loss: 1.3703\n",
      "Epoch23: loss: 0.1607 val_loss: 1.2864\n",
      "Epoch24: loss: 0.1730 val_loss: 1.2613\n",
      "Epoch25: loss: 0.1640 val_loss: 1.5746\n",
      "Epoch26: loss: 0.0889 val_loss: 1.3622\n",
      "Epoch27: loss: 0.1577 val_loss: 1.4786\n",
      "Epoch28: loss: 0.0732 val_loss: 1.6590\n",
      "Epoch29: loss: 0.1125 val_loss: 1.6471\n",
      "Early stopped training at epoch 29\n",
      "Accuracy of the network on the 211 train images: 98.1 %\n",
      "Accuracy of the network on the 24 val images: 66.7 %\n",
      "f1score of the network on the train: 0.99 \n",
      "f1score of the network on the val: 0.62 \n",
      "fold: 3 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.9480 val_loss: 0.9142\n",
      "Epoch2: loss: 0.8017 val_loss: 0.9540\n",
      "Epoch3: loss: 0.6216 val_loss: 0.9875\n",
      "Epoch4: loss: 0.6189 val_loss: 0.9291\n",
      "Epoch5: loss: 0.4784 val_loss: 1.0832\n",
      "Epoch6: loss: 0.3978 val_loss: 0.9917\n",
      "Epoch7: loss: 0.4333 val_loss: 0.9724\n",
      "Epoch8: loss: 0.3002 val_loss: 1.2680\n",
      "Epoch9: loss: 0.3976 val_loss: 1.2512\n",
      "Epoch10: loss: 0.3806 val_loss: 1.1904\n",
      "Epoch11: loss: 0.2595 val_loss: 1.3840\n",
      "Epoch12: loss: 0.3893 val_loss: 1.5481\n",
      "Epoch13: loss: 0.2386 val_loss: 1.4107\n",
      "Epoch14: loss: 0.3079 val_loss: 1.8166\n",
      "Epoch15: loss: 0.2735 val_loss: 1.6915\n",
      "Epoch16: loss: 0.2431 val_loss: 1.4641\n",
      "Epoch17: loss: 0.1777 val_loss: 1.7295\n",
      "Early stopped training at epoch 17\n",
      "Accuracy of the network on the 211 train images: 94.3 %\n",
      "Accuracy of the network on the 24 val images: 79.2 %\n",
      "f1score of the network on the train: 0.94 \n",
      "f1score of the network on the val: 0.69 \n",
      "fold: 4 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.8947 val_loss: 0.9655\n",
      "Epoch2: loss: 0.7626 val_loss: 0.8919\n",
      "Epoch3: loss: 0.5927 val_loss: 0.8292\n",
      "Epoch4: loss: 0.5783 val_loss: 0.9554\n",
      "Epoch5: loss: 0.4861 val_loss: 0.9575\n",
      "Epoch6: loss: 0.4269 val_loss: 0.7562\n",
      "Epoch7: loss: 0.4559 val_loss: 0.7565\n",
      "Epoch8: loss: 0.3378 val_loss: 0.8345\n",
      "Epoch9: loss: 0.3224 val_loss: 1.0453\n",
      "Epoch10: loss: 0.3151 val_loss: 0.8327\n",
      "Epoch11: loss: 0.3317 val_loss: 0.6866\n",
      "Epoch12: loss: 0.2393 val_loss: 0.9265\n",
      "Epoch13: loss: 0.2611 val_loss: 1.0940\n",
      "Epoch14: loss: 0.3577 val_loss: 0.9301\n",
      "Epoch15: loss: 0.1844 val_loss: 0.8612\n",
      "Epoch16: loss: 0.1743 val_loss: 1.0977\n",
      "Epoch17: loss: 0.2783 val_loss: 0.9059\n",
      "Epoch18: loss: 0.2734 val_loss: 0.9512\n",
      "Epoch19: loss: 0.3929 val_loss: 1.4021\n",
      "Epoch20: loss: 0.2156 val_loss: 0.8953\n",
      "Epoch21: loss: 0.2080 val_loss: 0.9002\n",
      "Epoch22: loss: 0.1171 val_loss: 1.0104\n",
      "Epoch23: loss: 0.1813 val_loss: 1.1494\n",
      "Epoch24: loss: 0.1727 val_loss: 1.2394\n",
      "Epoch25: loss: 0.1124 val_loss: 1.1326\n",
      "Epoch26: loss: 0.1178 val_loss: 0.8980\n",
      "Epoch27: loss: 0.1061 val_loss: 0.8033\n",
      "Early stopped training at epoch 27\n",
      "Accuracy of the network on the 212 train images: 97.2 %\n",
      "Accuracy of the network on the 23 val images: 73.9 %\n",
      "f1score of the network on the train: 0.97 \n",
      "f1score of the network on the val: 0.72 \n",
      "fold: 5 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.9856 val_loss: 1.0178\n",
      "Epoch2: loss: 0.7486 val_loss: 0.9353\n",
      "Epoch3: loss: 0.7188 val_loss: 0.9689\n",
      "Epoch4: loss: 0.6240 val_loss: 0.8763\n",
      "Epoch5: loss: 0.4439 val_loss: 0.9077\n",
      "Epoch6: loss: 0.5196 val_loss: 0.8648\n",
      "Epoch7: loss: 0.4709 val_loss: 1.2009\n",
      "Epoch8: loss: 0.4687 val_loss: 0.9805\n",
      "Epoch9: loss: 0.4659 val_loss: 0.9822\n",
      "Epoch10: loss: 0.4579 val_loss: 1.1417\n",
      "Epoch11: loss: 0.3581 val_loss: 0.9792\n",
      "Epoch12: loss: 0.2810 val_loss: 0.7384\n",
      "Epoch13: loss: 0.2560 val_loss: 0.8700\n",
      "Epoch14: loss: 0.3201 val_loss: 0.9535\n",
      "Epoch15: loss: 0.2224 val_loss: 0.9601\n",
      "Epoch16: loss: 0.2375 val_loss: 1.0527\n",
      "Epoch17: loss: 0.2292 val_loss: 1.3030\n",
      "Epoch18: loss: 0.2138 val_loss: 0.9643\n",
      "Epoch19: loss: 0.1987 val_loss: 0.7888\n",
      "Epoch20: loss: 0.2311 val_loss: 1.2067\n",
      "Epoch21: loss: 0.1783 val_loss: 1.1597\n",
      "Epoch22: loss: 0.1963 val_loss: 0.7792\n",
      "Epoch23: loss: 0.1579 val_loss: 1.1459\n",
      "Epoch24: loss: 0.1935 val_loss: 1.3123\n",
      "Epoch25: loss: 0.1784 val_loss: 0.8884\n",
      "Epoch26: loss: 0.1338 val_loss: 0.9786\n",
      "Epoch27: loss: 0.1683 val_loss: 0.9722\n",
      "Epoch28: loss: 0.1448 val_loss: 0.8748\n",
      "Early stopped training at epoch 28\n",
      "Accuracy of the network on the 212 train images: 97.2 %\n",
      "Accuracy of the network on the 23 val images: 73.9 %\n",
      "f1score of the network on the train: 0.98 \n",
      "f1score of the network on the val: 0.51 \n",
      "fold: 6 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 1.0566 val_loss: 1.3298\n",
      "Epoch2: loss: 0.7661 val_loss: 1.2952\n",
      "Epoch3: loss: 0.6213 val_loss: 1.0620\n",
      "Epoch4: loss: 0.5363 val_loss: 1.0503\n",
      "Epoch5: loss: 0.4651 val_loss: 1.2220\n",
      "Epoch6: loss: 0.4035 val_loss: 1.2791\n",
      "Epoch7: loss: 0.3645 val_loss: 1.1877\n",
      "Epoch8: loss: 0.4356 val_loss: 1.4972\n",
      "Epoch9: loss: 0.4190 val_loss: 1.4221\n",
      "Epoch10: loss: 0.3516 val_loss: 1.1690\n",
      "Epoch11: loss: 0.2991 val_loss: 1.3408\n",
      "Epoch12: loss: 0.2482 val_loss: 1.4667\n",
      "Epoch13: loss: 0.1632 val_loss: 1.4554\n",
      "Epoch14: loss: 0.2851 val_loss: 1.2419\n",
      "Epoch15: loss: 0.2513 val_loss: 1.3038\n",
      "Epoch16: loss: 0.2934 val_loss: 1.1068\n",
      "Epoch17: loss: 0.2490 val_loss: 1.4362\n",
      "Epoch18: loss: 0.1942 val_loss: 1.5860\n",
      "Epoch19: loss: 0.3264 val_loss: 1.3377\n",
      "Epoch20: loss: 0.2089 val_loss: 1.1134\n",
      "Early stopped training at epoch 20\n",
      "Accuracy of the network on the 212 train images: 92.0 %\n",
      "Accuracy of the network on the 23 val images: 65.2 %\n",
      "f1score of the network on the train: 0.94 \n",
      "f1score of the network on the val: 0.59 \n",
      "fold: 7 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.9507 val_loss: 1.2975\n",
      "Epoch2: loss: 0.8008 val_loss: 1.2060\n",
      "Epoch3: loss: 0.5835 val_loss: 1.5052\n",
      "Epoch4: loss: 0.4754 val_loss: 1.5254\n",
      "Epoch5: loss: 0.5270 val_loss: 1.7784\n",
      "Epoch6: loss: 0.4343 val_loss: 1.8345\n",
      "Epoch7: loss: 0.3703 val_loss: 2.0554\n",
      "Epoch8: loss: 0.3779 val_loss: 2.1664\n",
      "Epoch9: loss: 0.3807 val_loss: 1.9989\n",
      "Epoch10: loss: 0.2970 val_loss: 1.7641\n",
      "Epoch11: loss: 0.2901 val_loss: 1.8044\n",
      "Epoch12: loss: 0.2394 val_loss: 1.8671\n",
      "Epoch13: loss: 0.2193 val_loss: 2.0018\n",
      "Epoch14: loss: 0.2264 val_loss: 2.0560\n",
      "Epoch15: loss: 0.2411 val_loss: 1.8832\n",
      "Epoch16: loss: 0.2311 val_loss: 2.3387\n",
      "Epoch17: loss: 0.3028 val_loss: 2.1123\n",
      "Epoch18: loss: 0.1589 val_loss: 2.2070\n",
      "Early stopped training at epoch 18\n",
      "Accuracy of the network on the 212 train images: 98.6 %\n",
      "Accuracy of the network on the 23 val images: 47.8 %\n",
      "f1score of the network on the train: 0.98 \n",
      "f1score of the network on the val: 0.49 \n",
      "fold: 8 done!\n",
      "<class 'generator'>\n",
      "Epoch1: loss: 0.8923 val_loss: 1.0005\n",
      "Epoch2: loss: 0.8041 val_loss: 0.7985\n",
      "Epoch3: loss: 0.6438 val_loss: 0.8671\n",
      "Epoch4: loss: 0.5874 val_loss: 0.9500\n",
      "Epoch5: loss: 0.5139 val_loss: 0.7993\n",
      "Epoch6: loss: 0.4425 val_loss: 1.0527\n",
      "Epoch7: loss: 0.3582 val_loss: 0.9164\n",
      "Epoch8: loss: 0.3646 val_loss: 0.7690\n",
      "Epoch9: loss: 0.4301 val_loss: 0.8910\n",
      "Epoch10: loss: 0.4116 val_loss: 0.8060\n",
      "Epoch11: loss: 0.2777 val_loss: 0.6367\n",
      "Epoch12: loss: 0.2510 val_loss: 0.7392\n",
      "Epoch13: loss: 0.2136 val_loss: 0.4571\n",
      "Epoch14: loss: 0.2483 val_loss: 0.6135\n",
      "Epoch15: loss: 0.2579 val_loss: 0.6750\n",
      "Epoch16: loss: 0.2768 val_loss: 0.9460\n",
      "Epoch17: loss: 0.2443 val_loss: 0.9770\n",
      "Epoch18: loss: 0.2218 val_loss: 0.6335\n",
      "Epoch19: loss: 0.1970 val_loss: 0.8211\n",
      "Epoch20: loss: 0.2224 val_loss: 0.8709\n",
      "Epoch21: loss: 0.1502 val_loss: 0.6430\n",
      "Epoch22: loss: 0.1776 val_loss: 0.7536\n",
      "Epoch23: loss: 0.1770 val_loss: 0.7485\n",
      "Epoch24: loss: 0.1348 val_loss: 0.5425\n",
      "Epoch25: loss: 0.1716 val_loss: 0.7344\n",
      "Epoch26: loss: 0.2163 val_loss: 0.8851\n",
      "Epoch27: loss: 0.1433 val_loss: 1.0805\n",
      "Epoch28: loss: 0.1047 val_loss: 1.4457\n",
      "Epoch29: loss: 0.1473 val_loss: 0.9915\n",
      "Early stopped training at epoch 29\n",
      "Accuracy of the network on the 212 train images: 98.6 %\n",
      "Accuracy of the network on the 23 val images: 78.3 %\n",
      "f1score of the network on the train: 0.99 \n",
      "f1score of the network on the val: 0.74 \n",
      "fold: 9 done!\n"
     ]
    }
   ],
   "source": [
    "# the paramters below were optimized\n",
    "# only the optimum parameters for the production model are used here\n",
    "\n",
    "Learning_rate = [1e-4] #[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 1e-5, 5e-6] \n",
    "#Drop_out = [0.2, 0.35, 0.5, 0.65, 0.75]\n",
    "Batch_size = [32] #[24, 32, 100]\n",
    "\n",
    "def cross_10_folds_cnn(train_val_X, train_val_Y):\n",
    "\n",
    "    best_train = []\n",
    "    best_val = []\n",
    "    best_trainf1 = []\n",
    "    best_valf1 =  []\n",
    "    best_variables = []\n",
    "    best_performance_record = []\n",
    "    for fold in range(10):\n",
    "        \n",
    "        model_path = f'classification/ImageNet/aug3/CNN/{fold}_model.pth'\n",
    "        group, train_X, train_Y, val_X, val_Y = stratified_train_test_group_kfold(train_val_X, train_val_Y, train_val_groups, n_splits=10, test_fold=fold)\n",
    "        #train_X, val_X, train_Y, val_Y = train_test_split(train_val_X, train_val_Y, test_size=0.1,stratify=train_val_Y,random_state=fold+30)#42\n",
    "        best_train_acc, best_val_acc, trainf1, valf1, best_record, hyper=cnn_class_gridsearch(train_X, train_Y, val_X, val_Y, Learning_rate, Batch_size, fold, model_path)\n",
    "        #best_train_acc, best_val_acc, trainf1, valf1, best_perf_record, hyper=cnn_class_train_fn(train_X, train_Y, val_X, val_Y, Learning_rate, Batch_size, fold)\n",
    "\n",
    "        best_train.append(best_train_acc)\n",
    "        best_val.append(best_val_acc)\n",
    "        best_trainf1.append(trainf1)\n",
    "        best_valf1.append(valf1)\n",
    "        best_variables.append(hyper)\n",
    "        best_performance_record.append(best_record)\n",
    "\n",
    "        print(f'fold: {fold} done!')\n",
    "    return best_train, best_val, best_trainf1, best_valf1,best_variables, best_performance_record\n",
    "\n",
    "\n",
    "best_train, best_val, best_trainf1, best_valf1, best_variables, best_performance_record = cross_10_folds_cnn(train_val_X, train_val_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55f09e",
   "metadata": {},
   "source": [
    "# 4. Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c38ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 27 test images: 74.1 %\n",
      "Accuracy of the network on the 27 test images: 70.4 %\n",
      "Accuracy of the network on the 27 test images: 66.7 %\n",
      "Accuracy of the network on the 27 test images: 59.3 %\n",
      "Accuracy of the network on the 27 test images: 59.3 %\n",
      "Accuracy of the network on the 27 test images: 63.0 %\n",
      "Accuracy of the network on the 27 test images: 74.1 %\n",
      "Accuracy of the network on the 27 test images: 70.4 %\n",
      "Accuracy of the network on the 27 test images: 51.9 %\n",
      "Accuracy of the network on the 27 test images: 70.4 %\n",
      "[74.07407407407408, 70.37037037037037, 66.66666666666667, 59.25925925925926, 59.25925925925926, 62.96296296296296, 74.07407407407408, 70.37037037037037, 51.851851851851855, 70.37037037037037]\n",
      "test_acc_mean: 65.926, std: 6.988\n",
      "......\n",
      "idx_cm:  [0, 6]\n",
      "max_test_acc:  74.07407407407408\n",
      "[[ 0  3  0]\n",
      " [ 1 11  1]\n",
      " [ 1  1  9]]\n",
      "5th confusion matrix:  [[1, 2, 0], [2, 6, 5], [0, 2, 9]]\n",
      "10\n",
      "avg cm:  [[0.9, 1.9, 0.2], [1.8, 8.3, 2.9], [0.9, 1.5, 8.6]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model = pretrained_model()\n",
    "root_path = f'classification/ImageNet/aug3/CNN'\n",
    "\n",
    "best_test, confusion_matrix_test = cnn_class_cross_val_final_test(trained_model, test_X, test_Y, 'test', root_path)\n",
    "\n",
    "\n",
    "print(best_test)\n",
    "print(f'test_acc_mean: {np.mean(best_test) :.3f}, std: {np.std(best_test) :.3f}')\n",
    "print(\"......\")\n",
    "\n",
    "def cm_to_plot(best_test):\n",
    "\n",
    "    max_test = np.max(best_test)\n",
    "    idx_cm = []\n",
    "    for index, item in enumerate(best_test):\n",
    "        if item == max_test:\n",
    "            idx_cm.append(index)\n",
    "\n",
    "    print('idx_cm: ', idx_cm)\n",
    "    print('max_test_acc: ', max_test)\n",
    "\n",
    "    print(confusion_matrix_test[idx_cm[0]])\n",
    "cm_to_plot(best_test)\n",
    "print('5th confusion matrix: ', [list(item) for item in confusion_matrix_test[4]])\n",
    "\n",
    "\n",
    "cm_list = []\n",
    "for cm in confusion_matrix_test:\n",
    "    cm_list.append([list(item) for item in cm])\n",
    "#print(cm_list)\n",
    "\n",
    "print(len(cm_list))\n",
    "print('avg cm: ', [list(item) for item in np.mean(cm_list, axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3830ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchvision] *",
   "language": "python",
   "name": "conda-env-torchvision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
